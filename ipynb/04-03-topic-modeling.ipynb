{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from mongo_aggregation_verbs import *\n",
    "\n",
    "from lib import create_mongo_client_to_database_collection\n",
    "\n",
    "collection_reference = create_mongo_client_to_database_collection('twitter', 'tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://alexisperrier.com/nlp/2015/09/16/segmentation_twitter_timelines_lda_vs_lsa.html\n",
    "- https://alexisperrier.com/nlp/2015/09/04/topic-modeling-of-twitter-followers.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 211518}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_empty_url_arrays = { MATCH : { \"entities.urls\" : [] } }\n",
    "\n",
    "list(collection_reference.aggregate(\n",
    "    [\n",
    "        match_empty_url_arrays,\n",
    "        { COUNT : \"text\" }\n",
    "    ]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_hashtags = ['job', 'jobs', 'hiring', 'careerarc']\n",
    "location_hashtags = ['california', 'losangeles', 'la', 'santamonica', 'glendale', 'paloalto']\n",
    "match_not_in_bad = { MATCH : { \"text\" : { \"$in\" : job_hashtags + location_hashtags } } }\n",
    "project_to_text_keep_id = { PROJECT : { \"text\" : \"$entities.hashtags.text\" } }\n",
    "project_to_id = { PROJECT : { \"_id\" : 1 } }\n",
    "\n",
    "bad_ids = list(collection_reference.aggregate(\n",
    "    [\n",
    "        match_non_empty_hashtag_arrays,\n",
    "        project_to_text_keep_id,\n",
    "        unwind_text,\n",
    "        project_to_lower,\n",
    "        match_not_in_bad,\n",
    "        project_to_id\n",
    "    ]\n",
    "))\n",
    "bad_ids[:10], len(bad_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_ids = [bad_id['_id'] for bad_id in bad_ids]\n",
    "bad_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_in_bad_ids = { \"$nin\" : bad_ids }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_in_bad_ids_and_no_url = { \n",
    "    \"_id\"           : not_in_bad_ids, \n",
    "    \"entities.urls\" : []\n",
    "}\n",
    "\n",
    "just_the_text = {\n",
    "    \"text\" : 1,\n",
    "    \"_id\"  : 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_reference.find_one(\n",
    "    not_in_bad_ids_and_no_url,\n",
    "    just_the_text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur  = collection_reference.find(\n",
    "    not_in_bad_ids_and_no_url,\n",
    "    just_the_text\n",
    ")\n",
    "\n",
    "tweets = [next(cur) for _ in range(20000)]\n",
    "tweet_text = pd.DataFrame(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tweet_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweet_text.text = tweet_text.text.str.replace('http\\S+|www.\\S+', '', case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf.fit(tweet_text.text)\n",
    "word_occurence = tfidf.transform(tweet_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 5590)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_occurence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yippie</th>\n",
       "      <th>transgender</th>\n",
       "      <th>wanna</th>\n",
       "      <th>strategy</th>\n",
       "      <th>juiceworlddd</th>\n",
       "      <th>gunarmdyne</th>\n",
       "      <th>ray507hotrims</th>\n",
       "      <th>newark</th>\n",
       "      <th>sophie2078</th>\n",
       "      <th>lavalecoleman</th>\n",
       "      <th>pavy</th>\n",
       "      <th>구체적</th>\n",
       "      <th>kdtrey5</th>\n",
       "      <th>bitcoin</th>\n",
       "      <th>البطيخ</th>\n",
       "      <th>maximo</th>\n",
       "      <th>super</th>\n",
       "      <th>논의하고</th>\n",
       "      <th>verified</th>\n",
       "      <th>5sos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   yippie  transgender  wanna  strategy  juiceworlddd  gunarmdyne  \\\n",
       "0     0.0          0.0    0.0       0.0           0.0         0.0   \n",
       "1     0.0          0.0    0.0       0.0           0.0         0.0   \n",
       "2     0.0          0.0    0.0       0.0           0.0         0.0   \n",
       "3     0.0          0.0    0.0       0.0           0.0         0.0   \n",
       "4     0.0          0.0    0.0       0.0           0.0         0.0   \n",
       "\n",
       "   ray507hotrims  newark  sophie2078  lavalecoleman  pavy  구체적  kdtrey5  \\\n",
       "0            0.0     0.0         0.0            0.0   0.0  0.0      0.0   \n",
       "1            0.0     0.0         0.0            0.0   0.0  0.0      0.0   \n",
       "2            0.0     0.0         0.0            0.0   0.0  0.0      0.0   \n",
       "3            0.0     0.0         0.0            0.0   0.0  0.0      0.0   \n",
       "4            0.0     0.0         0.0            0.0   0.0  0.0      0.0   \n",
       "\n",
       "   bitcoin  البطيخ  maximo  super  논의하고  verified  5sos  \n",
       "0      0.0     0.0     0.0    0.0   0.0       0.0   0.0  \n",
       "1      0.0     0.0     0.0    0.0   0.0       0.0   0.0  \n",
       "2      0.0     0.0     0.0    0.0   0.0       0.0   0.0  \n",
       "3      0.0     0.0     0.0    0.0   0.0       0.0   0.0  \n",
       "4      0.0     0.0     0.0    0.0   0.0       0.0   0.0  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = tfidf.get_feature_names()\n",
    "word_sample = random.sample(words, 20)\n",
    "word_occurence_m = pd.DataFrame(word_occurence, columns=words)\n",
    "word_occurence_m[word_sample].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(algorithm='randomized', n_components=500, n_iter=5,\n",
       "       random_state=None, tol=0.0)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = TruncatedSVD(500)\n",
    "lda.fit(word_occurence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_df = pd.DataFrame(lda.components_, columns=words).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_topic(lda_df, index, threshold):\n",
    "    return (lda_df[lda_df[index] > threshold][index]\n",
    "            .sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_topic(lda_df, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_topic(lda_df, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_topic(lda_df, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_topic(lda_df, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_topic(lda_df, 4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_topic(lda_df, 5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_topic(lda_df, 6, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_topic(lda_df, 7, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
